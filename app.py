from langchain_openai import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage
import streamlit as st
from dotenv import load_dotenv
import os
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

import streamlit as st

# LLMã‹ã‚‰ã®å¿œç­”ã‚’å–å¾—ã™ã‚‹é–¢æ•°
def get_llm_response(user_input, expert_type):
    # å°‚é–€å®¶ã«å¿œã˜ãŸã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è¨­å®š
    if expert_type == "å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼":
        system_message = SystemMessage(content="ã‚ãªãŸã¯å„ªã—ã„å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼ã§ã™ã€‚")
    elif expert_type == "æ­´å²å­¦è€…":
        system_message = SystemMessage(content="ã‚ãªãŸã¯çŸ¥è­˜è±Šå¯Œãªæ­´å²å­¦è€…ã§ã™ã€‚")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    human_message = HumanMessage(content=user_input)

    # ChatOpenAIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ä½œæˆ
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.7)

    # ãƒãƒ£ãƒƒãƒˆã®å®Ÿè¡Œ
    response = llm.invoke([system_message, human_message])

    return response.content

st.title("ğŸ’¬ å°‚é–€å®¶AIãƒãƒ£ãƒƒãƒˆã‚¢ãƒ—ãƒª")
st.write("ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§å°‚é–€å®¶ã‚’é¸ã³ã€è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

# å°‚é–€å®¶é¸æŠ
expert_type = st.radio(
    "ã©ã®å°‚é–€å®¶ã«è³ªå•ã—ã¾ã™ã‹ï¼Ÿ",
    ("å¿ƒç†ã‚«ã‚¦ãƒ³ã‚»ãƒ©ãƒ¼", "æ­´å²å­¦è€…")
)

# ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
user_input = st.text_area("è³ªå•å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

# é€ä¿¡ãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input:
        response = get_llm_response(user_input, expert_type)
        st.write("### å›ç­”:")
        st.write(response)
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

